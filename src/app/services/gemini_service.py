"""
Service for integration with Google Gemini AI using the new google-genai SDK
"""

import os
import asyncio
import tempfile

from typing import Optional
import logging

# New google-genai SDK import
from google import genai

from .storage_service import storage_service
from src.app.config import settings

logger = logging.getLogger(__name__)

class GeminiService:
    """Service for integration with Google Gemini AI"""

    MODEL_NAME = "gemini-2.0-flash-001"

    def __init__(self):
        self.api_key = settings.gemini_api_key
        self.client = None
        if not self.api_key:
            logger.info("GEMINI_API_KEY is not configured. Using simulated responses.")
        try:
            self.client = genai.Client(api_key=self.api_key)
            logger.info(
                f"Gemini configured correctly with API key: {self.api_key[:10]}..."
            )
        except Exception as e:
            logger.error(f"‚ùå Error configuring Gemini: {e}")
            logger.error(f"   API Key used: {self.api_key[:10]}...")

    async def generate_response(
        self,
        question_text: str,
        context_text: Optional[str] = None,
        context_type: str = "text",
        context_file_path: Optional[str] = None,
        action: str = "create",
    ) -> str:
        """
        Generate response using Gemini AI

        Args:
            question_text: Text of the question
            context_text: Text context (optional)
            context_type: Type of context (text or pdf)
            context_file_path: Path of the PDF file in MinIO (optional)
            action: Action that is being performed (create, update, recalculate)

        Returns:
            str: Response generated by Gemini
        """
        try:
            if not self.client:
                return self._simulate_response(question_text, context_type, action)

            if context_type == "pdf" and context_file_path:
                response = await self._generate_with_pdf(
                    question_text, context_file_path, action
                )
            else:
                response = await self._generate_with_text(
                    question_text, context_text, action
                )

            return response

        except Exception as e:
            error_msg = str(e)
            if "429" in error_msg or "quota" in error_msg.lower():
                logger.info(f"‚ö†Ô∏è  Gemini quota exceeded. Using simulated response.")
                logger.info(f"   Detalles: {error_msg[:100]}...")
            else:
                logger.error(f"‚ùå Error generating response with Gemini: {e}")
            raise Exception("Error in gemini service") from e

    def _build_prompt(
        self,
        question_text: str,
        context_text: Optional[str],
        context_type: str,
        action: str,
    ) -> str:
        """Build optimized prompt for specific university context"""

        action_instructions = {
            "create": "Responde √öNICAMENTE bas√°ndote en el contexto universitario proporcionado.",
            "update": "Actualiza la respuesta bas√°ndote EXCLUSIVAMENTE en el contexto universitario proporcionado.",
            "recalculate": "Recalcula la respuesta usando SOLO la informaci√≥n del contexto universitario proporcionado.",
        }

        instruction = action_instructions.get(action, action_instructions["create"])

        prompt = f"INSTRUCCI√ìN IMPORTANTE: {instruction}\n\n"
        prompt += f"Pregunta: {question_text}\n\n"

        if context_text and context_text.strip():
            source_info = (
                "extra√≠do de documento PDF"
                if context_type == "pdf"
                else "proporcionado"
            )
            prompt += f"CONTEXTO UNIVERSITARIO ({source_info}):\n{context_text}\n\n"

            prompt += """INSTRUCCIONES ESTRICTAS:
1. Responde √öNICAMENTE con informaci√≥n contenida en el contexto universitario proporcionado
2. NO agregues informaci√≥n externa, conocimiento general o datos de otras fuentes
3. Si el contexto no contiene informaci√≥n suficiente para responder completamente, indica claramente qu√© informaci√≥n espec√≠fica falta
4. Mant√©n un tono acad√©mico y profesional apropiado para el contexto universitario
5. Responde de manera directa y natural, sin mencionar que la informaci√≥n proviene del contexto proporcionado
6. Si la pregunta no puede responderse con el contexto dado, responde: "La informaci√≥n proporcionada en el contexto no es suficiente para responder esta pregunta. Se necesitar√≠a informaci√≥n adicional sobre [especifica qu√© informaci√≥n]."

Respuesta:"""

        else:
            prompt += """NOTA: No se ha proporcionado contexto universitario espec√≠fico para esta pregunta.

INSTRUCCIONES:
1. Indica claramente que no hay contexto universitario disponible
2. Explica que no puedes responder sin el contexto espec√≠fico de la instituci√≥n
3. Sugiere qu√© tipo de informaci√≥n universitaria ser√≠a necesaria
4. Mant√©n un tono acad√©mico y profesional

Respuesta:"""

        return prompt

    async def _generate_with_text(
        self, question_text: str, context_text: Optional[str], action: str
    ) -> str:
        """Generate response with text context"""
        prompt = self._build_prompt(question_text, context_text, "text", action)
        return await self._generate_with_gemini(prompt)

    async def _generate_with_pdf(
        self, question_text: str, context_file_path: str, action: str
    ) -> str:
        """Generate response with PDF file using genai.upload_file()"""
        try:
            logger.info(f"üìÑ Downloading PDF from MinIO: {context_file_path}")
            file_stream = storage_service.get_file_stream(context_file_path)

            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as temp_file:
                for chunk in file_stream:
                    temp_file.write(chunk)
                temp_file_path = temp_file.name

            try:
                logger.info(f"üì§ Uploading PDF to Gemini...")
                # New SDK: upload file using client
                uploaded_file = self.client.files.upload(file=temp_file_path)
                logger.info(f"‚úÖ PDF uploaded to Gemini: {uploaded_file.name}")

                action_instructions = {
                    "create": "Responde √öNICAMENTE bas√°ndote en el documento PDF universitario proporcionado.",
                    "update": "Actualiza la respuesta bas√°ndote EXCLUSIVAMENTE en el documento PDF universitario proporcionado.",
                    "recalculate": "Recalcula la respuesta usando SOLO la informaci√≥n del documento PDF universitario proporcionado.",
                }

                instruction = action_instructions.get(
                    action, action_instructions["create"]
                )

                prompt = f"""INSTRUCCI√ìN IMPORTANTE: {instruction}

Pregunta: {question_text}

INSTRUCCIONES ESTRICTAS:
1. Analiza el documento PDF universitario proporcionado
2. Responde √öNICAMENTE con informaci√≥n contenida en el documento
3. NO agregues informaci√≥n externa, conocimiento general o datos de otras fuentes
4. Si el documento no contiene informaci√≥n suficiente, indica qu√© informaci√≥n espec√≠fica falta
5. Mant√©n un tono acad√©mico y profesional apropiado para el contexto universitario
6. Responde de manera directa y natural, sin mencionar que la informaci√≥n proviene del documento proporcionado
7. Si la pregunta no puede responderse con el documento, responde: "La informaci√≥n en el documento no es suficiente para responder esta pregunta. Se necesitar√≠a informaci√≥n adicional sobre [especifica qu√© informaci√≥n]."

Respuesta:"""

                response = await self._generate_with_gemini_and_file(
                    prompt, uploaded_file
                )

                return response

            finally:
                if os.path.exists(temp_file_path):
                    os.unlink(temp_file_path)

        except Exception as e:
            logger.error(f"‚ùå Error processing PDF with Gemini: {e}")
            raise

    async def _generate_with_gemini_and_file(self, prompt: str, uploaded_file) -> str:
        """Generate answert based in a pdf file"""
        try:
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None, lambda: self.client.models.generate_content(
                    model=self.MODEL_NAME,
                    contents=[prompt, uploaded_file]
                )
            )

            if response and response.text:
                return response.text.strip()
            else:
                raise Exception("Empty response from Gemini")

        except Exception as e:
            logger.error(f"‚ùå Error generating with Gemini and file: {e}")
            raise

    async def _generate_with_gemini(self, prompt: str) -> str:
        """Generate response using Gemini asynchronously"""
        try:
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None, lambda: self.client.models.generate_content(
                    model=self.MODEL_NAME,
                    contents=prompt
                )
            )

            if response and response.text:
                return response.text.strip()
            else:
                raise Exception("Respuesta vac√≠a de Gemini")

        except Exception as e:
            logger.error(f"‚ùå Error en la generaci√≥n con Gemini: {e}")
            raise

    def _simulate_response(
        self, question_text: str, context_type: str, action: str
    ) -> str:
        """Generate simulated response when Gemini is not available"""
        action_messages = {
            "create": "Procesamiento completado",
            "update": "Actualizaci√≥n procesada",
            "recalculate": "Rec√°lculo completado",
        }

        action_msg = action_messages.get(action, "Procesamiento completado")

        return (
            f"{action_msg} para '{question_text[:50]}{'...' if len(question_text) > 50 else ''}'. "
            f"El sistema ha analizado el contexto de tipo {context_type} y ha generado esta respuesta "
            f"detallada que incorpora conocimiento relevante del dominio. La acci√≥n de {action} se "
            f"ejecut√≥ correctamente, resultando en una respuesta que combina precisi√≥n t√©cnica con "
            f"claridad comunicativa para el usuario final."
        )


gemini_service = GeminiService()
